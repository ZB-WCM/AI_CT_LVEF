{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Import Packages and Data Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690823808640
    }
   },
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "from azure.ai.ml.entities import AzureBlobDatastore\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "mi_client_id = ###\n",
    "micredential = DefaultAzureCredential(managed_identity_client_id=mi_client_id)\n",
    "ml_client = MLClient.from_config(credential=micredential)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690823813588
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    !pip install azureml\n",
    "    !pip install -U azureml-fsspec mltable\n",
    "    !pip install azure-ai-ml\n",
    "\n",
    "import pandas as pd\n",
    "from azureml.fsspec import AzureMachineLearningFileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690823813955
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "####\n",
    "\n",
    "# long-form datastore URI format\n",
    "base_uri = f'azureml://subscriptions/{subscription}/resourcegroups/{resource_group}/workspaces/{workspace}/datastores/{datastore_name}/paths/'\n",
    "print(base_uri)\n",
    "base_uri_0 = base_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690823817765
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "fs = AzureMachineLearningFileSystem(base_uri) # create the filesystem\n",
    "display(fs.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ###\n",
    "file_uri = base_uri + file_path\n",
    "\n",
    "fs = AzureMachineLearningFileSystem(file_uri) # create the filesystem\n",
    "display(fs.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load file indices into dataframe\n",
    "idx_uri = file_uri + ###\n",
    "print(idx_uri)\n",
    "\n",
    "idx_io = BytesIO()\n",
    "with AzureMachineLearningFileSystem(idx_uri).open(mode='rb') as fp:\n",
    "    idx_io.write(fp.read())\n",
    "idx_io.seek(0)\n",
    "df_dicom_linker = pd.read_parquet(idx_io)\n",
    "\n",
    "print(df_dicom_linker.shape)\n",
    "display(df_dicom_linker.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dicom_linker.columns)\n",
    "# Question: can we have a texonomy for the different fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique StudyInstanceUID: {len(set(list(df_dicom_linker['StudyInstanceUID'])))}\")\n",
    "unique_linker_StudyInstanceUID = set(df_dicom_linker['StudyInstanceUID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690823264642
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = ###\n",
    "file_uri = base_uri_0 + file_path\n",
    "print(file_uri)\n",
    "fs = AzureMachineLearningFileSystem(file_uri) # create the filesystem\n",
    "display(fs.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690823264642
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = ###\n",
    "file_uri = base_uri_0 + file_path\n",
    "print(file_uri)\n",
    "fs = AzureMachineLearningFileSystem(file_uri) # create the filesystem\n",
    "display(fs.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ###\n",
    "file_uri = base_uri + file_path\n",
    "\n",
    "fs = AzureMachineLearningFileSystem(file_uri) # create the filesystem\n",
    "display(fs.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690821903976
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Confirm this\n",
    "if 0:\n",
    "    import socket\n",
    "    print(socket.getaddrinfo('devcardioimagedatastore.blob.core.windows.net', 443)[0][-1][0])\n",
    "    print(socket.getaddrinfo('eus2prdimagingsharesa.blob.core.windows.net', 443)[0][-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690821904625
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Install these for regular and compressed DICOM pixel data\n",
    "    !pip install pylibjpeg pylibjpeg-libjpeg pydicom\n",
    "    !pip install python-gdcm\n",
    "    !pip install --upgrade numpy\n",
    "    !pip install pydicom\n",
    "    # Intalling pydicom may require either reinstallation or kernel restart\n",
    "    \n",
    "import pydicom\n",
    "import pandas as pd\n",
    "from azureml.fsspec import AzureMachineLearningFileSystem\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690822186808
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "# long-form datastore URI format\n",
    "base_uri = f'azureml://subscriptions/{subscription}/resourcegroups/{resource_group}/workspaces/{workspace}/datastores/{datastore_name}/paths/'\n",
    "path_uri = base_uri + ''\n",
    "print(path_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690822188590
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test load one DICOM\n",
    "filename=###\n",
    "file_uri = path_uri + filename\n",
    "print(file_uri)\n",
    "\n",
    "with AzureMachineLearningFileSystem(file_uri).open() as fp:\n",
    "    dcm_tags = pydicom.read_file(fp)\n",
    "    print(dcm_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dcm_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1690822368683
    }
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # Search for parquet file\n",
    "    fs = AzureMachineLearningFileSystem(path_uri)\n",
    "    path_found = None\n",
    "    for path in fs.ls():\n",
    "        if '.parquet' in path:\n",
    "            path_found = path\n",
    "            break\n",
    "    print(path_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_report_linker_joined = df_dicom_linker.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ###\n",
    "file_uri = base_uri_0 + file_path\n",
    "print(file_uri)\n",
    "fs = AzureMachineLearningFileSystem(file_uri) # create the filesystem\n",
    "display(fs.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnsts = [fn.split('/') for fn in fs.ls()]\n",
    "print(fnsts)\n",
    "fns = [fnst[-1] for fnst in fnsts ]\n",
    "print(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,fn in enumerate(fns):\n",
    "    # Load file indices into dataframe\n",
    "    idx_uri = file_uri + fn\n",
    "    print(idx_uri)\n",
    "\n",
    "    idx_io = BytesIO()\n",
    "    with AzureMachineLearningFileSystem(idx_uri).open(mode='rb') as fp:\n",
    "        idx_io.write(fp.read())\n",
    "    idx_io.seek(0)\n",
    "    df_aim_image_report = pd.read_parquet(idx_io)\n",
    "\n",
    "    print(df_aim_image_report.shape)\n",
    "    print(df_aim_image_report.columns)\n",
    "    display(df_aim_image_report.head())\n",
    "    \n",
    "    df_image_report_linker = pd.merge(df_aim_image_report, df_image_report_linker_joined, left_on='OrderID', right_on='Order_ID')\n",
    "    print(f\"df_image_report_linker shape: {df_image_report_linker.shape}\")\n",
    "    if i == 0:\n",
    "        df_image_report_linker_all = df_image_report_linker.copy(deep=True)\n",
    "    else:\n",
    "        df_image_report_linker_all = pd.concat([df_image_report_linker_all, df_image_report_linker], ignore_index=True)\n",
    "        \n",
    "print(f\"df_image_report_linker_all.shape {df_image_report_linker_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_image_report_linker_all.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique StudyIUID: {len(set(df_image_report_linker_all['StudyInstanceUID']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_report_linker_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ###\n",
    "file_uri = base_uri_0 + file_path\n",
    "print(file_uri)\n",
    "fs = AzureMachineLearningFileSystem(file_uri) # create the filesystem\n",
    "display(fs.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_uri = file_uri + ###\n",
    "idx_io = BytesIO()\n",
    "with AzureMachineLearningFileSystem(idx_uri).open(mode='rb') as fp:\n",
    "    idx_io.write(fp.read())\n",
    "idx_io.seek(0)\n",
    "df_ef0 = pd.read_parquet(idx_io)\n",
    "\n",
    "idx_uri = file_uri + ###\n",
    "idx_io = BytesIO()\n",
    "with AzureMachineLearningFileSystem(idx_uri).open(mode='rb') as fp:\n",
    "    idx_io.write(fp.read())\n",
    "idx_io.seek(0)\n",
    "df_ef1 = pd.read_parquet(idx_io)\n",
    "\n",
    "print(df_ef0.shape)\n",
    "display(df_ef0.head())\n",
    "\n",
    "print(df_ef1.shape)\n",
    "display(df_ef1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ef = pd.concat([df_ef0, df_ef1], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ef['study_dttm'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ef.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_uri = file_uri + ###\n",
    "idx_io = BytesIO()\n",
    "with AzureMachineLearningFileSystem(idx_uri).open(mode='rb') as fp:\n",
    "    idx_io.write(fp.read())\n",
    "idx_io.seek(0)\n",
    "df_es0 = pd.read_parquet(idx_io)\n",
    "\n",
    "idx_uri = file_uri + ###\n",
    "idx_io = BytesIO()\n",
    "with AzureMachineLearningFileSystem(idx_uri).open(mode='rb') as fp:\n",
    "    idx_io.write(fp.read())\n",
    "idx_io.seek(0)\n",
    "df_es1 = pd.read_parquet(idx_io)\n",
    "\n",
    "print(df_es0.shape)\n",
    "display(df_es0.head())\n",
    "\n",
    "print(df_es1.shape)\n",
    "display(df_es1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es = pd.concat([df_es0, df_es1], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ef.shape)\n",
    "display(df_es.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ef.columns)\n",
    "display(df_es.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ef_es = pd.merge(df_ef, df_es, left_on='study_key', right_on='study_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ef.shape)\n",
    "display(df_es.shape)\n",
    "display(df_ef_es.shape)\n",
    "display(df_ef_es.head())\n",
    "print(f\"Unique study_type: {set(df_ef_es['study_type'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"df_image_report_linker_all\")\n",
    "display(df_image_report_linker_all.shape)\n",
    "display(df_image_report_linker_all.columns)\n",
    "\n",
    "display(\"df_ef_es\")\n",
    "display(df_ef_es.shape)\n",
    "display(df_ef_es.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managed_identity_client_id should be the client id of the corresponding computing resource\n",
    "account_url = ###\n",
    "default_credential = DefaultAzureCredential(managed_identity_client_id=###)\n",
    "\n",
    "# Create the BlobServiceClient object\n",
    "blob_service_client = BlobServiceClient(account_url, credential=default_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_name = ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_image_report_linker_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_report_linker_all = df_image_report_linker_all.add_prefix('CT_')\n",
    "df_ef_es = df_ef_es.add_prefix('ECHO_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_report_linker_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ef_es.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CT_echo = pd.merge(df_image_report_linker_all, df_ef_es, left_on = 'CT_EMPI', right_on = 'ECHO_patient_empi_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CT_echo = df_CT_echo.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CT_echo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CT_echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_bytes = df_echo_IR_CT_linker_i.to_records().tobytes()\n",
    "blob_file_name = ###\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_file_name)\n",
    "print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + blob_file_name)\n",
    "blob_client.upload_blob(df_CT_echo.to_json().encode(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_file_name = ###\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_file_name)\n",
    "\n",
    "# Download the blob array file into memory (but not to local storage)\n",
    "download_stream = blob_client.download_blob()\n",
    "saved = pd.read_json(download_stream.readall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved.CT_StudyDttm_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved['CT_StudyDttm_x'] = pd.to_datetime(saved['CT_StudyDttm_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved.CT_StudyDttm_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved.CT_StudyDttm_x[0].second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
